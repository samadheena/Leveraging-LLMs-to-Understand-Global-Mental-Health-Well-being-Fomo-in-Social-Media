# Leveraging-LLMs-to-Understand-Global-Mental-Health-Well-being-Fomo-in-Social-Media
Table of Content
1.Overview
2.Inference Settings
3.Datasets
4.Models
5.Results
6.Fine-tuning Hyperparamters
In this work, we present the first comprehensive evaluation of multiple LLMs, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4, on various mental health prediction tasks via online text data. We conduct a broad range of experiments, covering zero-shot prompting, few-shot prompting, and instruction fine-tuning. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously.
